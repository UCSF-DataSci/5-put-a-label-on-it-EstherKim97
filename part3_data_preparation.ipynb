{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5278978e",
   "metadata": {},
   "source": [
    "# Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "944c8f05",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas<3.0,>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.2.5)\n",
      "Requirement already satisfied: scikit-learn<2.0,>=1.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.6.1)\n",
      "Requirement already satisfied: xgboost<3.0,>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (2.1.4)\n",
      "Requirement already satisfied: imbalanced-learn<1.0,>=0.9 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (0.13.0)\n",
      "Requirement already satisfied: matplotlib<4.0,>=3.5 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (3.10.1)\n",
      "Requirement already satisfied: seaborn<1.0,>=0.11 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (0.13.2)\n",
      "Requirement already satisfied: ipykernel in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (6.29.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas<3.0,>=1.5->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas<3.0,>=1.5->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas<3.0,>=1.5->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn<2.0,>=1.0->-r requirements.txt (line 4)) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn<2.0,>=1.0->-r requirements.txt (line 4)) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn<2.0,>=1.0->-r requirements.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/codespace/.local/lib/python3.12/site-packages (from xgboost<3.0,>=1.5->-r requirements.txt (line 5)) (2.26.5)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /home/codespace/.local/lib/python3.12/site-packages (from imbalanced-learn<1.0,>=0.9->-r requirements.txt (line 6)) (0.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0,>=3.5->-r requirements.txt (line 7)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0,>=3.5->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0,>=3.5->-r requirements.txt (line 7)) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0,>=3.5->-r requirements.txt (line 7)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0,>=3.5->-r requirements.txt (line 7)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0,>=3.5->-r requirements.txt (line 7)) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0,>=3.5->-r requirements.txt (line 7)) (3.2.3)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (1.8.14)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (9.2.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (1.6.0)\n",
      "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (26.4.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (5.14.3)\n",
      "Requirement already satisfied: decorator in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.6.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 9)) (4.3.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.5->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/codespace/.local/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/codespace/.local/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/codespace/.local/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/codespace/.local/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1093058",
   "metadata": {},
   "source": [
    "# Part 3: Practical Data Preparation\n",
    "\n",
    "**Objective:** Handle categorical features using One-Hot Encoding and address class imbalance using SMOTE.\n",
    "\n",
    "## 1. Setup\n",
    "\n",
    "Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e78f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbe60ca",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09e2c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load the synthetic health data from a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the CSV file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing the data\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Load the CSV file using pandas\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    return df  # Replace with actual implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a28c53",
   "metadata": {},
   "source": [
    "## 3. Categorical Feature Encoding\n",
    "\n",
    "Implement `encode_categorical_features` using `OneHotEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d2d3454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_features(df, column_to_encode='smoker_status'):\n",
    "    \"\"\"\n",
    "    Encode a categorical column using OneHotEncoder.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        column_to_encode: Name of the categorical column to encode\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with the categorical column replaced by one-hot encoded columns\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # 1. Extract the column to encode\n",
    "    categorical_values = df[[column_to_encode]]\n",
    "\n",
    "    # 2. Apply OneHotEncoder\n",
    "    encoder = OneHotEncoder(sparse_output = False, drop='first')\n",
    "    encoded_array = encoder.fit_transform(categorical_values)\n",
    "\n",
    "    # 3. Create new column names\n",
    "    new_cols = encoder.get_feature_names_out([column_to_encode])\n",
    "    encoded_df = pd.DataFrame(encoded_array, columns=new_cols, index=df.index)\n",
    "\n",
    "    # 4. Replace the original column with new encoded columns\n",
    "    df_encoded = df.drop(columns=[column_to_encode])\n",
    "    df_encoded = pd.concat([df_encoded, encoded_df], axis=1)\n",
    "\n",
    "    # Placeholder return - replace with your implementation\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9b0b55cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>disease_outcome</th>\n",
       "      <th>smoker_status_no</th>\n",
       "      <th>smoker_status_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-29 00:00:00.000000</td>\n",
       "      <td>57</td>\n",
       "      <td>113.063416</td>\n",
       "      <td>84.069561</td>\n",
       "      <td>117.475210</td>\n",
       "      <td>25.085796</td>\n",
       "      <td>62.719587</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-31 07:33:55.507789</td>\n",
       "      <td>57</td>\n",
       "      <td>121.598849</td>\n",
       "      <td>89.672279</td>\n",
       "      <td>85.120875</td>\n",
       "      <td>24.120608</td>\n",
       "      <td>76.314434</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-02 00:15:11.379377</td>\n",
       "      <td>57</td>\n",
       "      <td>126.623222</td>\n",
       "      <td>87.619685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.819332</td>\n",
       "      <td>62.427785</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-04 09:37:12.589164</td>\n",
       "      <td>57</td>\n",
       "      <td>136.999366</td>\n",
       "      <td>89.199774</td>\n",
       "      <td>118.755648</td>\n",
       "      <td>25.039598</td>\n",
       "      <td>61.612981</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-04 20:56:52.838198</td>\n",
       "      <td>57</td>\n",
       "      <td>127.546919</td>\n",
       "      <td>92.644673</td>\n",
       "      <td>98.882007</td>\n",
       "      <td>24.895024</td>\n",
       "      <td>77.649615</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7321</th>\n",
       "      <td>150</td>\n",
       "      <td>2023-03-18 09:08:49.029823</td>\n",
       "      <td>54</td>\n",
       "      <td>115.038254</td>\n",
       "      <td>79.241741</td>\n",
       "      <td>84.586944</td>\n",
       "      <td>29.968156</td>\n",
       "      <td>73.599447</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7322</th>\n",
       "      <td>150</td>\n",
       "      <td>2023-03-20 14:38:22.129593</td>\n",
       "      <td>54</td>\n",
       "      <td>116.389186</td>\n",
       "      <td>70.464818</td>\n",
       "      <td>91.476621</td>\n",
       "      <td>29.519510</td>\n",
       "      <td>64.162701</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7323</th>\n",
       "      <td>150</td>\n",
       "      <td>2023-03-23 09:26:04.210673</td>\n",
       "      <td>54</td>\n",
       "      <td>123.419606</td>\n",
       "      <td>88.213054</td>\n",
       "      <td>96.985434</td>\n",
       "      <td>29.786678</td>\n",
       "      <td>71.641423</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7324</th>\n",
       "      <td>150</td>\n",
       "      <td>2023-03-27 14:17:19.255961</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.539940</td>\n",
       "      <td>85.670800</td>\n",
       "      <td>29.188655</td>\n",
       "      <td>72.781243</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7325</th>\n",
       "      <td>150</td>\n",
       "      <td>2023-04-12 04:12:38.529880</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.992331</td>\n",
       "      <td>94.694986</td>\n",
       "      <td>29.347033</td>\n",
       "      <td>66.888451</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7326 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id                   timestamp  age  systolic_bp  diastolic_bp  \\\n",
       "0              1  2023-01-29 00:00:00.000000   57   113.063416     84.069561   \n",
       "1              1  2023-01-31 07:33:55.507789   57   121.598849     89.672279   \n",
       "2              1  2023-02-02 00:15:11.379377   57   126.623222     87.619685   \n",
       "3              1  2023-02-04 09:37:12.589164   57   136.999366     89.199774   \n",
       "4              1  2023-02-04 20:56:52.838198   57   127.546919     92.644673   \n",
       "...          ...                         ...  ...          ...           ...   \n",
       "7321         150  2023-03-18 09:08:49.029823   54   115.038254     79.241741   \n",
       "7322         150  2023-03-20 14:38:22.129593   54   116.389186     70.464818   \n",
       "7323         150  2023-03-23 09:26:04.210673   54   123.419606     88.213054   \n",
       "7324         150  2023-03-27 14:17:19.255961   54          NaN     69.539940   \n",
       "7325         150  2023-04-12 04:12:38.529880   54          NaN     76.992331   \n",
       "\n",
       "      glucose_level        bmi  heart_rate  disease_outcome  smoker_status_no  \\\n",
       "0        117.475210  25.085796   62.719587                0               1.0   \n",
       "1         85.120875  24.120608   76.314434                0               1.0   \n",
       "2               NaN  24.819332   62.427785                0               1.0   \n",
       "3        118.755648  25.039598   61.612981                0               1.0   \n",
       "4         98.882007  24.895024   77.649615                0               1.0   \n",
       "...             ...        ...         ...              ...               ...   \n",
       "7321      84.586944  29.968156   73.599447                0               1.0   \n",
       "7322      91.476621  29.519510   64.162701                0               1.0   \n",
       "7323      96.985434  29.786678   71.641423                0               1.0   \n",
       "7324      85.670800  29.188655   72.781243                0               1.0   \n",
       "7325      94.694986  29.347033   66.888451                0               1.0   \n",
       "\n",
       "      smoker_status_yes  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "...                 ...  \n",
       "7321                0.0  \n",
       "7322                0.0  \n",
       "7323                0.0  \n",
       "7324                0.0  \n",
       "7325                0.0  \n",
       "\n",
       "[7326 rows x 11 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_categorical_features(df, column_to_encode='smoker_status')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d0c36d",
   "metadata": {},
   "source": [
    "## 4. Data Preparation\n",
    "\n",
    "Implement `prepare_data_part3` to handle the train/test split correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8e525023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_part3(df, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepare data with categorical encoding.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        test_size: Proportion of data for testing\n",
    "        random_state: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # 1. Encode categorical features using the encode_categorical_features function\n",
    "    df_encoded = encode_categorical_features(df, column_to_encode='smoker_status')\n",
    "\n",
    "    # 2. Select relevant features (including the one-hot encoded ones) and the target\n",
    "    feature_cols = [\n",
    "        'age', 'systolic_bp', 'diastolic_bp', 'glucose_level', 'bmi', 'heart_rate',\n",
    "        'disease_outcome', 'smoker_status_no', 'smoker_status_yes'\n",
    "    ]\n",
    "\n",
    "    encoded_cols = [col for col in df_encoded.columns if col.startswith('smoker_status_')]\n",
    "    features = feature_cols + encoded_cols\n",
    "\n",
    "    X = df_encoded[features]\n",
    "    y = df_encoded['disease_outcome']\n",
    "\n",
    "    # 3. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # 4. Handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_test = imputer.transform(X_test)\n",
    "\n",
    "    # Placeholder return - replace with your implementation\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e9853e",
   "metadata": {},
   "source": [
    "## 5. Handling Imbalanced Data\n",
    "\n",
    "Implement `apply_smote` to oversample the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca2da6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_smote(X_train, y_train, random_state=42):\n",
    "    \"\"\"\n",
    "    Apply SMOTE to oversample the minority class.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training target\n",
    "        random_state: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        Resampled X_train and y_train with balanced classes\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Apply SMOTE to balance the classes\n",
    "    smote = SMOTE(random_state=random_state)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Placeholder return - replace with your implementation\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32286ad2",
   "metadata": {},
   "source": [
    "## 6. Model Training and Evaluation\n",
    "\n",
    "Train a model on the SMOTE-resampled data and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "984b0300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training target\n",
    "        \n",
    "    Returns:\n",
    "        Trained logistic regression model\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Initialize and train a LogisticRegression model\n",
    "    model = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "\n",
    "    return model  # Replace with actual implementation\n",
    "\n",
    "def calculate_evaluation_metrics(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Calculate classification evaluation metrics.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        X_test: Test features\n",
    "        y_test: Test target\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing accuracy, precision, recall, f1, auc, and confusion_matrix\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # 1. Generate predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # 2. Calculate metrics: accuracy, precision, recall, f1, auc\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    # 3. Create confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # 4. Return metrics in a dictionary\n",
    "    # Placeholder return - replace with your implementation\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'auc': auc,\n",
    "        'confusion_matrix': cm\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a1a03a",
   "metadata": {},
   "source": [
    "## 7. Save Results\n",
    "\n",
    "Save the evaluation metrics to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "28d7846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# 1. Create 'results' directory if it doesn't exist\n",
    "# 2. Format metrics as strings\n",
    "# 3. Write metrics to 'results/results_part3.txt'\n",
    "\n",
    "def save_evaluation_metrics(metrics):\n",
    "    # 1. Create 'results' directory if it doesn't exist\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "\n",
    "    # 2. Format metrics as strings\n",
    "    metrics_str = \"# Logistic Regression Evaluation Metrics – Part 3\\n\\n\"\n",
    "    metrics_str += '\\n'.join(\n",
    "        f'{key}: {value:.4f}' if np.isscalar(value) else f'{key}:\\n{np.array2string(value, precision=4)}'\n",
    "        for key, value in metrics.items()\n",
    "    )\n",
    "\n",
    "    # 3. Write metrics to 'results/results_part3.txt'\n",
    "    with open(os.path.join('results', 'results_part3.txt'), 'w') as f:\n",
    "        f.write(metrics_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2433399",
   "metadata": {},
   "source": [
    "## 8. Main Execution\n",
    "\n",
    "Run the complete workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c52ca565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000\n",
      "precision: 1.0000\n",
      "recall: 1.0000\n",
      "f1_score: 1.0000\n",
      "auc: 1.0000\n",
      "\n",
      "Model Comparison (improvement percentages):\n",
      "accuracy: 9.08%\n",
      "precision: 51.17%\n",
      "recall: 232.56%\n",
      "f1_score: N/A\n",
      "auc: 10.08%\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Load data\n",
    "    data_file = 'data/synthetic_health_data.csv'\n",
    "    df = load_data(data_file)\n",
    "    \n",
    "    # 2. Prepare data with categorical encoding\n",
    "    X_train, X_test, y_train, y_test = prepare_data_part3(df)\n",
    "    \n",
    "    # 3. Apply SMOTE to balance the training data\n",
    "    X_train_resampled, y_train_resampled = apply_smote(X_train, y_train)\n",
    "    \n",
    "    # 4. Train model on resampled data\n",
    "    model = train_logistic_regression(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # 5. Evaluate on original test set\n",
    "    metrics = calculate_evaluation_metrics(model, X_test, y_test)\n",
    "    \n",
    "    # 6. Print metrics\n",
    "    for metric, value in metrics.items():\n",
    "        if metric != 'confusion_matrix':\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # 7. Save results\n",
    "    # (Your code for saving results)\n",
    "    save_evaluation_metrics(metrics)\n",
    "\n",
    "    # 8. Load Part 1 results for comparison\n",
    "\n",
    "    # NOTE: kept getting JSONDecodeError\n",
    "    # import json\n",
    "    # try:\n",
    "    #     with open('results/results_part1.txt', 'r') as f:\n",
    "    #         part1_metrics = json.load(f)\n",
    "    # 8. Load Part 1 results for comparison\n",
    "    try:\n",
    "    # Read metrics from file directly without json\n",
    "        part1_metrics = {}\n",
    "        with open('results/results_part1.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                if ':' in line:\n",
    "                    key, value = line.strip().split(':')\n",
    "                    key = key.strip().lower()\n",
    "                    value = value.strip()  \n",
    "\n",
    "                    if key == \"confusion_matrix\":\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        try:\n",
    "                            value = float(value)\n",
    "                        except ValueError:\n",
    "                            pass\n",
    "\n",
    "                    part1_metrics[key] = value\n",
    "\n",
    "        # 9. Compare models\n",
    "        comparison = compare_models(part1_metrics, metrics)\n",
    "        print(\"\\nModel Comparison (improvement percentages):\")\n",
    "        for metric, improvement in comparison.items():\n",
    "            if improvement is None:\n",
    "                print(f\"{metric}: N/A\")\n",
    "            else:\n",
    "                print(f\"{metric}: {improvement:.2f}%\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"Part 1 results not found. Run part1_introduction.ipynb first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc785f",
   "metadata": {},
   "source": [
    "## 9. Compare Results\n",
    "\n",
    "Implement a function to compare model performance between balanced and imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d803c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(part1_metrics, part3_metrics):\n",
    "    \"\"\"\n",
    "    Calculate percentage improvement between models trained on imbalanced vs. balanced data.\n",
    "    \n",
    "    Args:\n",
    "        part1_metrics: Dictionary containing evaluation metrics from Part 1 (imbalanced)\n",
    "        part3_metrics: Dictionary containing evaluation metrics from Part 3 (balanced)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with metric names as keys and improvement percentages as values\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # 1. Calculate percentage improvement for each metric\n",
    "    # 2. Handle metrics where higher is better (most metrics) and where lower is better\n",
    "    # 3. Return a dictionary with metric names and improvement percentages\n",
    "    \n",
    "    improvements = {}\n",
    "    \n",
    "    # Define metrics to compare (skip confusion_matrix)\n",
    "    for metric in ['accuracy', 'precision', 'recall', 'f1_score', 'auc']:\n",
    "        val1 = part1_metrics.get(metric)\n",
    "        val3 = part3_metrics.get(metric)\n",
    "        \n",
    "        if val1 is None or val3 is None:\n",
    "            improvements[metric] = None\n",
    "            continue\n",
    "\n",
    "        if val1 == 0:\n",
    "            improvements[metric] = float('inf')\n",
    "        else:\n",
    "            improvements[metric] = ((val3 - val1) / abs(val1)) * 100\n",
    "    \n",
    "    return improvements"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
