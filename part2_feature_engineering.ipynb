{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ef2412b",
   "metadata": {},
   "source": [
    "# Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea08cbe4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas<3.0,>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.2.5)\n",
      "Requirement already satisfied: scikit-learn<2.0,>=1.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.6.1)\n",
      "Requirement already satisfied: xgboost<3.0,>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (2.1.4)\n",
      "Requirement already satisfied: imbalanced-learn<1.0,>=0.9 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (0.13.0)\n",
      "Requirement already satisfied: matplotlib<4.0,>=3.5 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (3.10.1)\n",
      "Requirement already satisfied: seaborn<1.0,>=0.11 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (0.13.2)\n",
      "Requirement already satisfied: ipykernel in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (6.29.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas<3.0,>=1.5->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas<3.0,>=1.5->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas<3.0,>=1.5->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn<2.0,>=1.0->-r requirements.txt (line 4)) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn<2.0,>=1.0->-r requirements.txt (line 4)) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn<2.0,>=1.0->-r requirements.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/codespace/.local/lib/python3.12/site-packages (from xgboost<3.0,>=1.5->-r requirements.txt (line 5)) (2.26.5)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /home/codespace/.local/lib/python3.12/site-packages (from imbalanced-learn<1.0,>=0.9->-r requirements.txt (line 6)) (0.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0,>=3.5->-r requirements.txt (line 7)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0,>=3.5->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0,>=3.5->-r requirements.txt (line 7)) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0,>=3.5->-r requirements.txt (line 7)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0,>=3.5->-r requirements.txt (line 7)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0,>=3.5->-r requirements.txt (line 7)) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0,>=3.5->-r requirements.txt (line 7)) (3.2.3)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (1.8.14)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (9.2.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (1.6.0)\n",
      "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (26.4.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (5.14.3)\n",
      "Requirement already satisfied: decorator in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.6.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 9)) (4.3.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.5->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/codespace/.local/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/codespace/.local/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/codespace/.local/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/codespace/.local/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3badd7e",
   "metadata": {},
   "source": [
    "# Part 2: Time Series Features & Tree-Based Models\n",
    "\n",
    "**Objective:** Extract basic time-series features from heart rate data, train Random Forest and XGBoost models, and compare their performance.\n",
    "\n",
    "## 1. Setup\n",
    "\n",
    "Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30c70b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca95a43",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a29e4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load the synthetic health data from a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the CSV file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing the data with timestamp parsed as datetime\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Load the CSV file using pandas\n",
    "    # Make sure to parse the timestamp column as datetime\n",
    "    data = pd.read_csv(file_path, parse_dates=[\"timestamp\"])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adff7b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      patient_id                  timestamp  age  systolic_bp  diastolic_bp  \\\n",
      "0              1 2023-01-29 00:00:00.000000   57   113.063416     84.069561   \n",
      "1              1 2023-01-31 07:33:55.507789   57   121.598849     89.672279   \n",
      "2              1 2023-02-02 00:15:11.379377   57   126.623222     87.619685   \n",
      "3              1 2023-02-04 09:37:12.589164   57   136.999366     89.199774   \n",
      "4              1 2023-02-04 20:56:52.838198   57   127.546919     92.644673   \n",
      "...          ...                        ...  ...          ...           ...   \n",
      "7321         150 2023-03-18 09:08:49.029823   54   115.038254     79.241741   \n",
      "7322         150 2023-03-20 14:38:22.129593   54   116.389186     70.464818   \n",
      "7323         150 2023-03-23 09:26:04.210673   54   123.419606     88.213054   \n",
      "7324         150 2023-03-27 14:17:19.255961   54          NaN     69.539940   \n",
      "7325         150 2023-04-12 04:12:38.529880   54          NaN     76.992331   \n",
      "\n",
      "      glucose_level        bmi smoker_status  heart_rate  disease_outcome  \n",
      "0        117.475210  25.085796            no   62.719587                0  \n",
      "1         85.120875  24.120608            no   76.314434                0  \n",
      "2               NaN  24.819332            no   62.427785                0  \n",
      "3        118.755648  25.039598            no   61.612981                0  \n",
      "4         98.882007  24.895024            no   77.649615                0  \n",
      "...             ...        ...           ...         ...              ...  \n",
      "7321      84.586944  29.968156            no   73.599447                0  \n",
      "7322      91.476621  29.519510            no   64.162701                0  \n",
      "7323      96.985434  29.786678            no   71.641423                0  \n",
      "7324      85.670800  29.188655            no   72.781243                0  \n",
      "7325      94.694986  29.347033            no   66.888451                0  \n",
      "\n",
      "[7326 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "df = load_data('data/synthetic_health_data.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5b2309",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Implement `extract_rolling_features` to calculate rolling mean and standard deviation for the `heart_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "828c7431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rolling_features(df, window_size_seconds):\n",
    "    \"\"\"\n",
    "    Calculate rolling mean and standard deviation for heart rate.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with timestamp and heart_rate columns\n",
    "        window_size_seconds: Size of the rolling window in seconds\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with added hr_rolling_mean and hr_rolling_std columns\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # 1. Sort data by timestamp\n",
    "    df_sorted = df.sort_values('timestamp')\n",
    "    \n",
    "    # 2. Set timestamp as index (this allows time-based operations)\n",
    "    df_indexed = df_sorted.set_index('timestamp')\n",
    "    \n",
    "    # 3. Calculate rolling mean and standard deviation\n",
    "    #    - First, create a rolling window object based on time:\n",
    "    rolling_window = df_indexed['heart_rate'].rolling(window=f'{window_size_seconds}s')\n",
    "    #    - Then calculate statistics on this window:\n",
    "    hr_mean = rolling_window.mean()\n",
    "    hr_std = rolling_window.std()\n",
    "    \n",
    "    # 4. Add the new columns back to the dataframe\n",
    "    df_indexed['hr_rolling_mean'] = hr_mean\n",
    "    df_indexed['hr_rolling_std'] = hr_std\n",
    "    \n",
    "    # 5. Reset index to bring timestamp back as a column\n",
    "    df_result = df_indexed.reset_index()\n",
    "    \n",
    "    # 6. Handle any NaN values (rolling calculations create NaNs at the beginning)\n",
    "    #    - You can use fillna, dropna, or other methods depending on your strategy\n",
    "    df_result = df_result.bfill()\n",
    "    \n",
    "    # Placeholder return - replace with your implementation\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a54a30ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      timestamp  patient_id  age  systolic_bp  diastolic_bp  \\\n",
      "0    2023-01-01 00:00:00.000000           9   42   109.271202     84.872277   \n",
      "1    2023-01-01 00:00:00.000000          72   73   117.499246     80.624776   \n",
      "2    2023-01-01 00:00:00.000000         131   26   125.396859     75.090352   \n",
      "3    2023-01-01 00:00:00.000000         116   54   124.532627     78.492678   \n",
      "4    2023-01-02 00:00:00.000000          56   63   111.304514     67.796714   \n",
      "...                         ...         ...  ...          ...           ...   \n",
      "7321 2023-07-20 21:01:11.701224         109   53   130.694575     74.261794   \n",
      "7322 2023-07-23 01:45:47.772214           5   46   108.477241     88.742732   \n",
      "7323 2023-07-23 06:55:40.341291          16   41   124.742455     83.196582   \n",
      "7324 2023-08-03 10:54:11.976978         109   53   130.912449     69.467888   \n",
      "7325 2023-08-05 13:16:36.634428          90   57   133.101666     82.658927   \n",
      "\n",
      "      glucose_level        bmi smoker_status  heart_rate  disease_outcome  \\\n",
      "0        112.205979  28.723817        former   65.241827                0   \n",
      "1        113.018091  22.543094            no   75.405997                0   \n",
      "2        108.999820  23.975127           yes   71.244470                0   \n",
      "3         78.559751  25.783712            no   76.660696                0   \n",
      "4         97.859274  27.611658            no   63.534376                0   \n",
      "...             ...        ...           ...         ...              ...   \n",
      "7321     107.862114  21.732533            no   71.660907                0   \n",
      "7322      99.719007  33.010116            no   65.398427                0   \n",
      "7323     117.215513  27.210364            no   73.129839                0   \n",
      "7324     118.815102  22.172972            no   67.511809                0   \n",
      "7325     110.289272  28.277001           yes   60.008615                0   \n",
      "\n",
      "      hr_rolling_mean  hr_rolling_std  \n",
      "0           65.241827        7.187153  \n",
      "1           70.323912        7.187153  \n",
      "2           70.630764        5.109800  \n",
      "3           72.138247        5.147497  \n",
      "4           63.534376        2.716776  \n",
      "...               ...             ...  \n",
      "7321        71.660907             NaN  \n",
      "7322        65.398427             NaN  \n",
      "7323        73.129839             NaN  \n",
      "7324        67.511809             NaN  \n",
      "7325        60.008615             NaN  \n",
      "\n",
      "[7326 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "rolling_df = extract_rolling_features(df, 1)\n",
    "print(rolling_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f939412",
   "metadata": {},
   "source": [
    "## 4. Data Preparation\n",
    "\n",
    "Implement `prepare_data_part2` using the newly engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "659b5207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_part2(df_with_features, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepare data for modeling with time-series features.\n",
    "    \n",
    "    Args:\n",
    "        df_with_features: DataFrame with original and rolling features\n",
    "        test_size: Proportion of data for testing\n",
    "        random_state: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # 1. Select relevant features including rolling features\n",
    "    feature_cols = ['age', 'systolic_bp', 'diastolic_bp', 'glucose_level', 'bmi', 'heart_rate', 'hr_rolling_mean', 'hr_rolling_std']\n",
    "    \n",
    "    # 2. Select target variable\n",
    "    target_col = 'disease_outcome'\n",
    "    \n",
    "    # 3. Drop rows with missing values in the selected columns\n",
    "    df_cleaned = df_with_features.dropna(subset=feature_cols + [target_col])\n",
    "    \n",
    "    # 4. Extract features and target\n",
    "    X = df_cleaned[feature_cols]\n",
    "    y = df_cleaned[target_col]\n",
    "    \n",
    "    # 5. Split data into train/test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Placeholder return - replace with your implementation\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf1b0d",
   "metadata": {},
   "source": [
    "## 5. Random Forest Model\n",
    "\n",
    "Implement `train_random_forest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "306969a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(X_train, y_train, n_estimators=100, max_depth=10, random_state=42):\n",
    "    \"\"\"\n",
    "    Train a Random Forest classifier.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training target\n",
    "        n_estimators: Number of trees in the forest\n",
    "        max_depth: Maximum depth of the trees\n",
    "        random_state: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        Trained Random Forest model\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Initialize and train a RandomForestClassifier\n",
    "    rf_model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n",
    "    \n",
    "    # Train the model\n",
    "    rf_model_ = rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    return rf_model_  # Replace with actual implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdf24b9",
   "metadata": {},
   "source": [
    "## 6. XGBoost Model\n",
    "\n",
    "Implement `train_xgboost`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6228ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(X_train, y_train, n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Train an XGBoost classifier.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training target\n",
    "        n_estimators: Number of boosting rounds\n",
    "        learning_rate: Boosting learning rate\n",
    "        max_depth: Maximum depth of a tree\n",
    "        random_state: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        Trained XGBoost model\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Initialize and train an XGBClassifier\n",
    "    xgb_model = xgb.XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=random_state, eval_metric='logloss')\n",
    "    \n",
    "    # Train the model\n",
    "    xgb_model_ = xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    return xgb_model_  # Replace with actual implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095718f7",
   "metadata": {},
   "source": [
    "## 7. Model Comparison\n",
    "\n",
    "Calculate and compare AUC scores for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30892885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# 1. Generate probability predictions for both models\n",
    "# 2. Calculate AUC scores\n",
    "# 3. Compare the performance\n",
    "\n",
    "def compare_models(rf_model, xgb_model, X_test, y_test):\n",
    "    # 1. Generate probability predictions for both models\n",
    "    rf_probs = rf_model.predict_proba(X_test)[:, 1]  # Probability of class 1\n",
    "    xgb_probs = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # 2. Calculate AUC scores\n",
    "    rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "    xgb_auc = roc_auc_score(y_test, xgb_probs)\n",
    "\n",
    "    # 3. Compare the performance\n",
    "    print(f\"Random Forest AUC: {rf_auc:.4f}\")\n",
    "    print(f\"XGBoost AUC: {xgb_auc:.4f}\")\n",
    "    if rf_auc > xgb_auc:\n",
    "        print(\"Random Forest performed better than XGBoost model.\")\n",
    "    elif xgb_auc > rf_auc:\n",
    "        print(\"→ XGBoost performed better than Random Forest model.\")\n",
    "    else:\n",
    "        print(\"→ Both models performed equally.\")\n",
    "\n",
    "    return rf_auc, xgb_auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae7b4cc",
   "metadata": {},
   "source": [
    "## 8. Save Results\n",
    "\n",
    "Save the AUC scores to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58591242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# 1. Create 'results' directory if it doesn't exist\n",
    "# 2. Format AUC scores as strings\n",
    "# 3. Write scores to 'results/results_part2.txt'\n",
    "\n",
    "def save_auc_scores(rf_auc, xgb_auc):\n",
    "    # 1. Create 'results' directory if it doesn't exist\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "\n",
    "    # 2. Format AUC scores as strings\n",
    "    # 3. Write scores to 'results/results_part2.txt'\n",
    "    with open('results/results_part2.txt', 'w') as f:\n",
    "        f.write(\"# AUC Scores - Part 2\\n\\n\")\n",
    "        f.write(f\"Random Forest AUC: {rf_auc:.4f}\" + \"\\n\")\n",
    "        f.write(f\"XGBoost AUC: {xgb_auc:.4f}\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6194c95",
   "metadata": {},
   "source": [
    "## 9. Main Execution\n",
    "\n",
    "Run the complete workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6416131f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest AUC: 0.9758\n",
      "XGBoost AUC: 0.9956\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Load data\n",
    "    data_file = 'data/synthetic_health_data.csv'\n",
    "    df = load_data(data_file)\n",
    "    \n",
    "    # 2. Extract rolling features\n",
    "    window_size = 300  # 5 minutes in seconds\n",
    "    df_with_features = extract_rolling_features(df, window_size)\n",
    "    \n",
    "    # 3. Prepare data\n",
    "    X_train, X_test, y_train, y_test = prepare_data_part2(df_with_features)\n",
    "    \n",
    "    # 4. Train models\n",
    "    rf_model = train_random_forest(X_train, y_train)\n",
    "    xgb_model = train_xgboost(X_train, y_train)\n",
    "    \n",
    "    # 5. Calculate AUC scores\n",
    "    rf_probs = rf_model.predict_proba(X_test)[:, 1]\n",
    "    xgb_probs = xgb_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "    xgb_auc = roc_auc_score(y_test, xgb_probs)\n",
    "    \n",
    "    print(f\"Random Forest AUC: {rf_auc:.4f}\")\n",
    "    print(f\"XGBoost AUC: {xgb_auc:.4f}\")\n",
    "\n",
    "    # 6. Save results\n",
    "    # (Your code for saving results)\n",
    "    save_auc_scores(rf_auc, xgb_auc)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
